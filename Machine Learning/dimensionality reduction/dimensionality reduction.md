## Dimensionality Reduction
Working with datasets composed of only two independent variables allows for:
- Having two dimensions to visualize better how Machine Learning models worked 
(by plotting the prediction regions and the prediction boundary for each model).
- Having the original number of our independent variables, we can often end up with 
two independent variables by applying an appropriate Dimensionality Reduction technique.

There are two types of Dimensionality Reduction techniques:
- Feature Selection (Backward Elimination, Forward Selection, 
Bidirectional Elimination, Score Comparison and more)
- Feature Extraction (Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA),
Kernel PCA, Quadratic Discriminant Analysis (QDA)
